{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import recall_score, precision_score, accuracy_score, f1_score, confusion_matrix\n",
    "from sklearn.model_selection import cross_val_predict, cross_val_score, StratifiedKFold\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carrega base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "stroke_cat = pd.read_csv('stroke_df_cat')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>hypertension</th>\n",
       "      <th>heart_disease</th>\n",
       "      <th>ever_married</th>\n",
       "      <th>work_type</th>\n",
       "      <th>Residence_type</th>\n",
       "      <th>avg_glucose_level</th>\n",
       "      <th>bmi</th>\n",
       "      <th>smoking_status</th>\n",
       "      <th>stroke</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   gender  age  hypertension  heart_disease  ever_married  work_type  \\\n",
       "0       1   28             0              0             1          2   \n",
       "1       1   33             0              0             1          2   \n",
       "2       0   42             0              0             1          2   \n",
       "3       1   56             0              0             1          2   \n",
       "4       0   24             0              0             0          2   \n",
       "\n",
       "   Residence_type  avg_glucose_level  bmi  smoking_status  stroke  \n",
       "0               1                  1    1               2       0  \n",
       "1               0                  1    4               1       0  \n",
       "2               0                  2    3               0       0  \n",
       "3               1                  1    5               2       0  \n",
       "4               0                  1    5               2       0  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stroke_cat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorizar_idade(value):\n",
    "  if value <= 18:\n",
    "    return 0\n",
    "  elif 18 < value <= 30:\n",
    "    return 1\n",
    "  elif 30 < value <= 60:\n",
    "    return 2\n",
    "  else:\n",
    "    return 3\n",
    "\n",
    "stroke_cat['age'] = stroke_cat['age'].apply(categorizar_idade)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>hypertension</th>\n",
       "      <th>heart_disease</th>\n",
       "      <th>ever_married</th>\n",
       "      <th>work_type</th>\n",
       "      <th>Residence_type</th>\n",
       "      <th>avg_glucose_level</th>\n",
       "      <th>bmi</th>\n",
       "      <th>smoking_status</th>\n",
       "      <th>stroke</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   gender  age  hypertension  heart_disease  ever_married  work_type  \\\n",
       "0       1    1             0              0             1          2   \n",
       "1       1    2             0              0             1          2   \n",
       "2       0    2             0              0             1          2   \n",
       "3       1    2             0              0             1          2   \n",
       "4       0    1             0              0             0          2   \n",
       "\n",
       "   Residence_type  avg_glucose_level  bmi  smoking_status  stroke  \n",
       "0               1                  1    1               2       0  \n",
       "1               0                  1    4               1       0  \n",
       "2               0                  2    3               0       0  \n",
       "3               1                  1    5               2       0  \n",
       "4               0                  1    5               2       0  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stroke_cat.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrada para modelagem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#features\n",
    "\n",
    "X = (stroke_cat.drop(['stroke','gender','ever_married','work_type','Residence_type','smoking_status'], axis=1)).values\n",
    "\n",
    "#target\n",
    "\n",
    "y = (stroke_cat['stroke']).values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Criação dos modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "ad_clf = DecisionTreeClassifier()\n",
    "knn_clf = KNeighborsClassifier(n_neighbors = 5)\n",
    "rf_clf = RandomForestClassifier(n_estimators=100)\n",
    "lg_clf = LogisticRegression(random_state=0, max_iter=1000)\n",
    "mlp_clf = MLPClassifier(random_state=1, max_iter=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Amostragem Holdout teste dos modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    95.845119\n",
      "1     4.154881\n",
      "Name: count, dtype: float64\n",
      "10253\n"
     ]
    }
   ],
   "source": [
    "y_train_v =  pd.DataFrame(y_train)\n",
    "print(y_train_v.value_counts()/y_train_v.shape[0]*100)\n",
    "print(y_train_v.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_s, X_test_s, y_train_s, y_test_s = train_test_split(X, y, test_size = 0.33,stratify=y)\n",
    "\n",
    "#stratify, a função train_test_split garante que a divisão dos dados em conjuntos de treinamento e teste mantém a mesma distribuição das classes em y nos dois conjuntos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    95.874378\n",
      "1     4.125622\n",
      "Name: count, dtype: float64\n",
      "10253\n"
     ]
    }
   ],
   "source": [
    "y_train_v =  pd.DataFrame(y_train_s)\n",
    "print(y_train_v.value_counts()/y_train_v.shape[0]*100)\n",
    "print(y_train_v.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "s=SMOTE()\n",
    "X_reso,y_reso =s.fit_resample(X_train,y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    50.0\n",
      "1    50.0\n",
      "Name: count, dtype: float64\n",
      "19654\n"
     ]
    }
   ],
   "source": [
    "y_train_v =  pd.DataFrame(y_reso)\n",
    "print(y_train_v.value_counts()/y_train_v.shape[0]*100)\n",
    "print(y_train_v.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import ClusterCentroids,RandomUnderSampler\n",
    "\n",
    "rus= RandomUnderSampler()\n",
    "cc = ClusterCentroids()\n",
    "\n",
    "X_resu,y_resu = rus.fit_resample(X_train,y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    50.0\n",
      "1    50.0\n",
      "Name: count, dtype: float64\n",
      "852\n"
     ]
    }
   ],
   "source": [
    "y_train_v =  pd.DataFrame(y_resu)\n",
    "print(y_train_v.value_counts()/y_train_v.shape[0]*100)\n",
    "print(y_train_v.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Treinar modelos - com Holdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   Modelo  Accuracy  Precision    Recall  F1-Score\n",
      "0  DecisionTreeClassifier  0.957822   0.230769  0.014563  0.027397\n",
      "1    KNeighborsClassifier  0.943762   0.157895  0.087379  0.112500\n",
      "2  RandomForestClassifier  0.956832   0.166667  0.014563  0.026786\n",
      "3      LogisticRegression  0.959406   1.000000  0.004854  0.009662\n",
      "4           MLPClassifier  0.958812   0.375000  0.014563  0.028037\n"
     ]
    }
   ],
   "source": [
    "modelos = [ad_clf, knn_clf, rf_clf, lg_clf, mlp_clf]\n",
    "\n",
    "# Dicionário para armazenar métricas\n",
    "metrics = {\"Modelo\": [], \"Accuracy\": [], \"Precision\": [], \"Recall\": [], \"F1-Score\": []}\n",
    "\n",
    "for modelo in modelos:\n",
    "    modelo.fit(X_train, y_train)\n",
    "    y_pred = modelo.predict(X_test)\n",
    "    \n",
    "    modelo_name = modelo.__class__.__name__\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    \n",
    "    metrics[\"Modelo\"].append(modelo_name)\n",
    "    metrics[\"Accuracy\"].append(accuracy)\n",
    "    metrics[\"Precision\"].append(precision)\n",
    "    metrics[\"Recall\"].append(recall)\n",
    "    metrics[\"F1-Score\"].append(f1)\n",
    "\n",
    "# Exiba as métricas\n",
    "\n",
    "metrics_df = pd.DataFrame(metrics)\n",
    "print(metrics_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Treinar modelos - com Holdout stratify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   Modelo  Accuracy  Precision    Recall  F1-Score\n",
      "0  DecisionTreeClassifier  0.957228   0.315789  0.028708  0.052632\n",
      "1    KNeighborsClassifier  0.950099   0.179104  0.057416  0.086957\n",
      "2  RandomForestClassifier  0.957228   0.315789  0.028708  0.052632\n",
      "3      LogisticRegression  0.958614   0.000000  0.000000  0.000000\n",
      "4           MLPClassifier  0.958614   0.000000  0.000000  0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "modelos = [ad_clf, knn_clf, rf_clf, lg_clf, mlp_clf]\n",
    "\n",
    "# Dicionário para armazenar métricas\n",
    "metrics = {\"Modelo\": [], \"Accuracy\": [], \"Precision\": [], \"Recall\": [], \"F1-Score\": []}\n",
    "\n",
    "for modelo in modelos:\n",
    "    modelo.fit(X_train_s, y_train_s)\n",
    "    y_pred = modelo.predict(X_test_s)\n",
    "    \n",
    "    modelo_name = modelo.__class__.__name__\n",
    "    accuracy = accuracy_score(y_test_s, y_pred)\n",
    "    precision = precision_score(y_test_s, y_pred)\n",
    "    recall = recall_score(y_test_s, y_pred)\n",
    "    f1 = f1_score(y_test_s, y_pred)\n",
    "    \n",
    "    metrics[\"Modelo\"].append(modelo_name)\n",
    "    metrics[\"Accuracy\"].append(accuracy)\n",
    "    metrics[\"Precision\"].append(precision)\n",
    "    metrics[\"Recall\"].append(recall)\n",
    "    metrics[\"F1-Score\"].append(f1)\n",
    "\n",
    "# Exiba as métricas\n",
    "\n",
    "metrics_df = pd.DataFrame(metrics)\n",
    "print(metrics_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Treinar modelos com  o KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   Modelo  Accuracy  Precision    Recall  F1-Score\n",
      "0  DecisionTreeClassifier  0.957786   0.121429  0.011061  0.014820\n",
      "1    KNeighborsClassifier  0.955630   0.333869  0.037958  0.083627\n",
      "2  RandomForestClassifier  0.957786   0.164286  0.014211  0.015130\n",
      "3      LogisticRegression  0.958701   0.000000  0.000000  0.000000\n",
      "4           MLPClassifier  0.958636   0.150000  0.004762  0.006154\n"
     ]
    }
   ],
   "source": [
    "modelos = [ad_clf, knn_clf, rf_clf, lg_clf, mlp_clf]\n",
    "\n",
    "\n",
    "metrics = {\"Modelo\": [], \"Accuracy\": [], \"Precision\": [], \"Recall\": [], \"F1-Score\": []}\n",
    "\n",
    "# Realize a validação cruzada e calcule as métricas para cada modelo\n",
    "for modelo in modelos:\n",
    "    \n",
    "    modelo_name = modelo.__class__.__name__ \n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True)   \n",
    "   \n",
    "    y_pred = cross_val_predict(modelo, X, y, cv=skf)\n",
    "    \n",
    "    # Calcule as métricas\n",
    "    \n",
    "    accuracy = cross_val_score(modelo, X, y, cv=skf, scoring='accuracy').mean()\n",
    "    precision = cross_val_score(modelo, X, y, cv=skf, scoring='precision').mean()\n",
    "    recall = cross_val_score(modelo, X, y, cv=skf, scoring='recall').mean()\n",
    "    f1 = cross_val_score(modelo, X, y, cv=skf, scoring='f1').mean()\n",
    "    \n",
    "    # Armazene as métricas no dicionário\n",
    "    metrics[\"Modelo\"].append(modelo_name)\n",
    "    metrics[\"Accuracy\"].append(accuracy)\n",
    "    metrics[\"Precision\"].append(precision)\n",
    "    metrics[\"Recall\"].append(recall)\n",
    "    metrics[\"F1-Score\"].append(f1)\n",
    "\n",
    "# Exiba as métricas\n",
    "import pandas as pd\n",
    "metrics_df = pd.DataFrame(metrics)\n",
    "print(metrics_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Treinar modelos com  Holdout e undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   Modelo  Accuracy  Precision    Recall  F1-Score\n",
      "0  DecisionTreeClassifier  0.782970   0.122241  0.699029  0.208092\n",
      "1    KNeighborsClassifier  0.905347   0.166667  0.330097  0.221498\n",
      "2  RandomForestClassifier  0.778614   0.125616  0.742718  0.214888\n",
      "3      LogisticRegression  0.809703   0.142180  0.728155  0.237906\n",
      "4           MLPClassifier  0.785545   0.133054  0.771845  0.226981\n"
     ]
    }
   ],
   "source": [
    "modelos = [ad_clf, knn_clf, rf_clf, lg_clf, mlp_clf]\n",
    "\n",
    "# Dicionário para armazenar métricas\n",
    "metrics = {\"Modelo\": [], \"Accuracy\": [], \"Precision\": [], \"Recall\": [], \"F1-Score\": []}\n",
    "\n",
    "for modelo in modelos:\n",
    "    modelo.fit(X_resu, y_resu)\n",
    "    y_pred = modelo.predict(X_test)\n",
    "    \n",
    "    modelo_name = modelo.__class__.__name__\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    \n",
    "    metrics[\"Modelo\"].append(modelo_name)\n",
    "    metrics[\"Accuracy\"].append(accuracy)\n",
    "    metrics[\"Precision\"].append(precision)\n",
    "    metrics[\"Recall\"].append(recall)\n",
    "    metrics[\"F1-Score\"].append(f1)\n",
    "\n",
    "# Exiba as métricas\n",
    "\n",
    "metrics_df = pd.DataFrame(metrics)\n",
    "print(metrics_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Treinar modelos com  Holdout e oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   Modelo  Accuracy  Precision    Recall  F1-Score\n",
      "0  DecisionTreeClassifier  0.772673   0.117073  0.699029  0.200557\n",
      "1    KNeighborsClassifier  0.940000   0.160839  0.111650  0.131805\n",
      "2  RandomForestClassifier  0.772079   0.116788  0.699029  0.200139\n",
      "3      LogisticRegression  0.823564   0.147996  0.699029  0.244275\n",
      "4           MLPClassifier  0.797822   0.128532  0.684466  0.216424\n"
     ]
    }
   ],
   "source": [
    "modelos = [ad_clf, knn_clf, rf_clf, lg_clf, mlp_clf]\n",
    "\n",
    "# Dicionário para armazenar métricas\n",
    "metrics = {\"Modelo\": [], \"Accuracy\": [], \"Precision\": [], \"Recall\": [], \"F1-Score\": []}\n",
    "\n",
    "for modelo in modelos:\n",
    "    modelo.fit(X_reso, y_reso)\n",
    "    y_pred = modelo.predict(X_test)\n",
    "    \n",
    "    modelo_name = modelo.__class__.__name__\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    \n",
    "    metrics[\"Modelo\"].append(modelo_name)\n",
    "    metrics[\"Accuracy\"].append(accuracy)\n",
    "    metrics[\"Precision\"].append(precision)\n",
    "    metrics[\"Recall\"].append(recall)\n",
    "    metrics[\"F1-Score\"].append(f1)\n",
    "\n",
    "# Exiba as métricas\n",
    "\n",
    "metrics_df = pd.DataFrame(metrics)\n",
    "print(metrics_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Treinar modelos com  Kfold e undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   Modelo  Accuracy  Precision    Recall  F1-Score\n",
      "0  DecisionTreeClassifier  0.790174   0.136155  0.764104  0.230935\n",
      "1    KNeighborsClassifier  0.911324   0.182873  0.333883  0.236010\n",
      "2  RandomForestClassifier  0.781938   0.133397  0.778428  0.227702\n",
      "3      LogisticRegression  0.812520   0.149945  0.757818  0.250345\n",
      "4           MLPClassifier  0.806117   0.147501  0.772291  0.247610\n"
     ]
    }
   ],
   "source": [
    "modelos = [ad_clf, knn_clf, rf_clf, lg_clf, mlp_clf]\n",
    "metrics = {\"Modelo\": [], \"Accuracy\": [], \"Precision\": [], \"Recall\": [], \"F1-Score\": []}\n",
    "\n",
    "n_splits = 5\n",
    "cv = StratifiedKFold(n_splits=n_splits,shuffle=True)\n",
    "\n",
    "under = RandomUnderSampler()\n",
    "\n",
    "\n",
    "for modelo in modelos:\n",
    "\n",
    "    accuracies = []\n",
    "    precisions = []\n",
    "    recalls = []\n",
    "    f1s = []    \n",
    "\n",
    "    # Realize a validação cruzada com undersampling\n",
    "    for train_idx, test_idx in cv.split(X, y):\n",
    "        X_train, y_train = X[train_idx], y[train_idx]\n",
    "        X_test, y_test = X[test_idx], y[test_idx]\n",
    "        \n",
    "    # Realize o undersampling nos dados de treinamento\n",
    "        X_resampled, y_resampled =under.fit_resample(X_train, y_train)\n",
    "    \n",
    "        modelo_name = modelo.__class__.__name__  \n",
    "        modelo.fit(X_resampled, y_resampled)\n",
    "        y_pred = modelo.predict(X_test)\n",
    "    \n",
    "        modelo_name = modelo.__class__.__name__\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        precision = precision_score(y_test, y_pred)\n",
    "        recall = recall_score(y_test, y_pred)\n",
    "        f1 = f1_score(y_test, y_pred)\n",
    "        \n",
    "        accuracies.append(accuracy)\n",
    "        precisions.append(precision)\n",
    "        recalls.append(recall)\n",
    "        f1s.append(f1)\n",
    "        \n",
    "    mean_accuracy = sum(accuracies) / n_splits\n",
    "    mean_precision = sum(precisions) / n_splits\n",
    "    mean_recall = sum(recalls) / n_splits\n",
    "    mean_f1 = sum(f1s) / n_splits\n",
    "\n",
    "    # Armazene as métricas no dicionário\n",
    "    metrics[\"Modelo\"].append(modelo_name)\n",
    "    metrics[\"Accuracy\"].append(mean_accuracy)    \n",
    "    metrics[\"Precision\"].append(mean_precision)\n",
    "    metrics[\"Recall\"].append(mean_recall)\n",
    "    metrics[\"F1-Score\"].append(mean_f1)\n",
    "\n",
    "# Exiba as métricas\n",
    "\n",
    "metrics_df = pd.DataFrame(metrics)\n",
    "print(metrics_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Treinar modelos com  Kfold e oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   Modelo  Accuracy  Precision    Recall  F1-Score\n",
      "0  DecisionTreeClassifier  0.807685   0.140133  0.707287  0.233808\n",
      "1    KNeighborsClassifier  0.953343   0.272929  0.071216  0.111885\n",
      "2  RandomForestClassifier  0.806900   0.139430  0.707324  0.232858\n",
      "3      LogisticRegression  0.822649   0.154407  0.734171  0.255126\n",
      "4           MLPClassifier  0.803436   0.142650  0.745232  0.239322\n"
     ]
    }
   ],
   "source": [
    "modelos = [ad_clf, knn_clf, rf_clf, lg_clf, mlp_clf]\n",
    "metrics = {\"Modelo\": [], \"Accuracy\": [], \"Precision\": [], \"Recall\": [], \"F1-Score\": []}\n",
    "\n",
    "n_splits = 5\n",
    "cv = StratifiedKFold(n_splits=n_splits)\n",
    "over = SMOTE()\n",
    "\n",
    "\n",
    "for modelo in modelos:\n",
    "\n",
    "    accuracies = []\n",
    "    precisions = []\n",
    "    recalls = []\n",
    "    f1s = []    \n",
    "\n",
    "    # Realize a validação cruzada com undersampling\n",
    "    for train_idx, test_idx in cv.split(X, y):\n",
    "        X_train, y_train = X[train_idx], y[train_idx]\n",
    "        X_test, y_test = X[test_idx], y[test_idx]\n",
    "\n",
    "    # Realize o undersampling nos dados de treinamento\n",
    "        X_resampled, y_resampled =over.fit_resample(X_train, y_train)\n",
    "    \n",
    "        modelo_name = modelo.__class__.__name__  \n",
    "        modelo.fit(X_resampled, y_resampled)\n",
    "        y_pred = modelo.predict(X_test)\n",
    "    \n",
    "        modelo_name = modelo.__class__.__name__\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        precision = precision_score(y_test, y_pred)\n",
    "        recall = recall_score(y_test, y_pred)\n",
    "        f1 = f1_score(y_test, y_pred)\n",
    "        \n",
    "        accuracies.append(accuracy)\n",
    "        precisions.append(precision)\n",
    "        recalls.append(recall)\n",
    "        f1s.append(f1)\n",
    "        \n",
    "    mean_accuracy = sum(accuracies) / n_splits\n",
    "    mean_precision = sum(precisions) / n_splits\n",
    "    mean_recall = sum(recalls) / n_splits\n",
    "    mean_f1 = sum(f1s) / n_splits\n",
    "\n",
    "    # Armazene as métricas no dicionário\n",
    "    metrics[\"Modelo\"].append(modelo_name)\n",
    "    metrics[\"Accuracy\"].append(mean_accuracy)    \n",
    "    metrics[\"Precision\"].append(mean_precision)\n",
    "    metrics[\"Recall\"].append(mean_recall)\n",
    "    metrics[\"F1-Score\"].append(mean_f1)\n",
    "\n",
    "# Exiba as métricas\n",
    "\n",
    "metrics_df = pd.DataFrame(metrics)\n",
    "print(metrics_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo: Decision Tree\n",
      "Melhores Parâmetros: {'classifier__criterion': 'gini', 'classifier__max_depth': None, 'classifier__min_samples_split': 10}\n",
      "Recall: 0.784688995215311\n",
      "Modelo: Random Forest\n",
      "Melhores Parâmetros: {'classifier__criterion': 'gini', 'classifier__max_depth': None, 'classifier__min_samples_split': 10, 'classifier__n_estimators': 100}\n",
      "Recall: 0.7990430622009569\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo: MLP Classifier\n",
      "Melhores Parâmetros: {'classifier__activation': 'tanh', 'classifier__alpha': 0.01, 'classifier__hidden_layer_sizes': (100, 100, 50), 'classifier__learning_rate': 'adaptive', 'classifier__max_iter': 500}\n",
      "Recall: 0.8038277511961722\n",
      "Modelo: KNN\n",
      "Melhores Parâmetros: {'classifier__metric': 'euclidean', 'classifier__n_neighbors': 9, 'classifier__weights': 'distance'}\n",
      "Recall: 0.430622009569378\n",
      "Modelo: Logistic Regression\n",
      "Melhores Parâmetros: {'classifier__class_weight': 'balanced', 'classifier__max_iter': 1000}\n",
      "Recall: 0.7703349282296651\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:425: FitFailedWarning: \n",
      "10 fits failed out of a total of 20.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "10 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py\", line 1152, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\pipeline.py\", line 427, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py\", line 1145, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py\", line 638, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'class_weight' parameter of LogisticRegression must be an instance of 'dict', a str among {'balanced'} or None. Got 'none' instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:979: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.73747899 0.73747899]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from imblearn.under_sampling import ClusterCentroids,RandomUnderSampler\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.33, stratify=y)\n",
    "under = RandomUnderSampler()\n",
    "X_resampled, y_resampled =under.fit_resample(X_train, y_train)\n",
    "\n",
    "pipelines = {\n",
    "    'Decision Tree': Pipeline([\n",
    "        ('classifier', DecisionTreeClassifier())\n",
    "    ]),\n",
    "    'Random Forest': Pipeline([\n",
    "        ('classifier', RandomForestClassifier())\n",
    "    ]),\n",
    "    'MLP Classifier': Pipeline([\n",
    "        ('classifier', MLPClassifier())\n",
    "    ]),\n",
    "    'KNN': Pipeline([\n",
    "        ('classifier', KNeighborsClassifier())\n",
    "    ]),\n",
    "    'Logistic Regression': Pipeline([\n",
    "        ('classifier', LogisticRegression())\n",
    "    ]),\n",
    "}\n",
    "\n",
    "param_grids = {\n",
    "    'Decision Tree':{\n",
    "        'classifier__min_samples_split': [2,5,10],\n",
    "        'classifier__max_depth': [None, 5, 10, 15],\n",
    "        'classifier__criterion': ['gini', 'entropy']\n",
    "    },\n",
    "    'Random Forest':{\n",
    "        'classifier__min_samples_split': [2, 5, 10],\n",
    "        'classifier__n_estimators': [50,100,150],\n",
    "        'classifier__max_depth': [None, 5, 10, 15],\n",
    "        'classifier__criterion': ['gini', 'entropy']\n",
    "    },\n",
    "    'MLP Classifier':{\n",
    "        'classifier__hidden_layer_sizes': [(50,), (100,50), (100,100,50)],\n",
    "        'classifier__activation': ['identity', 'logistic', 'tanh', 'relu'],\n",
    "        'classifier__alpha': [0.0001, 0.001, 0.01],\n",
    "        'classifier__max_iter': [500],\n",
    "        'classifier__learning_rate': ['adaptive']\n",
    "    },\n",
    "    'KNN':{\n",
    "        'classifier__n_neighbors': [3,5,7,9],\n",
    "        'classifier__weights': ['uniform', 'distance'],\n",
    "        'classifier__metric': ['euclidean', 'manhattan']\n",
    "    },\n",
    "    'Logistic Regression':{\n",
    "        'classifier__max_iter': [1000,2000],\n",
    "        'classifier__class_weight': ['none', 'balanced']\n",
    "    }\n",
    "}\n",
    "\n",
    "scoring = ['precision', 'recall']\n",
    "for model_name, pipeline in pipelines.items():\n",
    "  \n",
    "  #grid_search = GridSearchCV(pipeline, param_grids[model_name], scoring=scoring, refit=False)  \n",
    "  grid_search = GridSearchCV(pipeline, param_grids[model_name], scoring='recall')\n",
    "  grid_search.fit(X_resampled, y_resampled)\n",
    "\n",
    "  best_params = grid_search.best_params_\n",
    "  best_model = grid_search.best_estimator_\n",
    "\n",
    "  y_pred = best_model.predict(X_test)\n",
    "  recall = recall_score(y_test, y_pred)\n",
    "\n",
    "  print(\"Modelo:\", model_name)\n",
    "  print(\"Melhores Parâmetros:\", best_params)\n",
    "  print(\"Recall:\", recall)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
